import logging
import sqlite3
import requests
from bs4 import BeautifulSoup
from flask import Flask, jsonify, request, render_template, send_from_directory
from sklearn.cluster import KMeans
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import IsolationForest
import openai
from user_agents import parse
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
import time
from flask import Flask, send_from_directory, render_template_string
import time
import threading
from flask import Flask, jsonify, send_from_directory
import os

app = Flask(__name__)

# ğŸ“Œ Ù†Ù…Ø§ÛŒØ´ ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ Ø³Ø§ÛŒØª
@app.route('/')
def home():
    return send_from_directory(os.getcwd(), "index.html")  # Ù„ÙˆØ¯ Ø§Ø² Ù¾ÙˆØ´Ù‡ ÙØ¹Ù„ÛŒ

# ğŸ“Œ API Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø§ÛŒØª
@app.route('/optimize')
def optimize():
    return jsonify({"message": "Website optimization started!"})

# ğŸ“Œ Ø³Ø±Ùˆ Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ§ØªÛŒÚ© (CSS, JS, Images)
@app.route('/<path:path>')
def static_files(path):
    return send_from_directory(os.getcwd(), path)  # Ù„ÙˆØ¯ Ù‡Ù…Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù¾ÙˆØ´Ù‡ ÙØ¹Ù„ÛŒ

# ğŸ“Œ ÙØ´Ø±Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ CSS Ùˆ JS (Ø­Ù„ Ù…Ø´Ú©Ù„ escape sequence)
@app.route('/compress')
def compress():
    os.system("find . -type f -name '*.css' -exec gzip {} ';'")
    os.system("find . -type f -name '*.js' -exec gzip {} ';'")
    return jsonify({"message": "Compression completed!"})

if __name__ == '__main__':
    app.run(debug=True)


class AIWebsiteOptimizer:
    def __init__(self):
        pass

    def start_monitoring(self):
        # Ø§Ø¬Ø±Ø§ÛŒ ØªØ§Ø¨Ø¹ Ø¨Ù‡ ØµÙˆØ±Øª Ø²Ù…Ø§Ù†Ø¨Ù†Ø¯ÛŒ Ø´Ø¯Ù‡ Ù‡Ø± 60 Ø«Ø§Ù†ÛŒÙ‡
        self.schedule_task()

    def schedule_task(self):
        # Ø§Ø¬Ø±Ø§ÛŒ ØªØ§Ø¨Ø¹ Ø¯Ø± Ù‡Ø± 60 Ø«Ø§Ù†ÛŒÙ‡
        threading.Timer(60.0, self.run_tasks).start()

    def run_tasks(self):
        self.scan_website()
        self.optimize_performance()
        self.enhance_security()
        self.adjust_ui_for_devices()
        # Ø¨Ø¹Ø¯ Ø§Ø² 60 Ø«Ø§Ù†ÛŒÙ‡ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ÙˆØ¸Ø§ÛŒÙ Ø§Ø¬Ø±Ø§ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯
        self.schedule_task()

    def scan_website(self):
        print("Scanning website for issues...")
        # ØªØ­Ù„ÛŒÙ„ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± AI Ø¨Ø±Ø§ÛŒ ÙˆØ¶Ø¹ÛŒØª ÙˆØ¨Ø³Ø§ÛŒØªØŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ØŒ Ùˆ SEO

    def optimize_performance(self):
        print("Optimizing website speed and efficiency...")
        # Ú©Ø´ÛŒÙ†Ú¯ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± AIØŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ ØªØµØ§ÙˆÛŒØ± Ùˆ Ù…ØªØ¹Ø§Ø¯Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø§Ø±

    def enhance_security(self):
        print("Enhancing website security and threat detection...")
        # Ø¯ÛŒÙˆØ§Ø± Ø¢ØªØ´ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± AIØŒ Ø­ÙØ§Ø¸Øª Ø§Ø² DDoS Ùˆ Ø§Ø³Ú©Ù† Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒâ€ŒÙ‡Ø§

    def adjust_ui_for_devices(self):
        print("Adjusting UI for all screen sizes and devices...")
        # Ø·Ø±Ø§Ø­ÛŒ ÙˆØ§Ú©Ù†Ø´â€ŒÚ¯Ø±Ø§ Ùˆ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ú†ÛŒØ¯Ù…Ø§Ù† Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± AI

# Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡
optimizer = AIWebsiteOptimizer()
optimizer.start_monitoring()


app = Flask(__name__)

# Ù…Ø³ÛŒØ± Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ index.html
@app.route('/')
def home():
    return render_template_string(open('index.html').read())  # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ… ÙØ§ÛŒÙ„ HTML Ø§Ø² Ù¾ÙˆØ´Ù‡ Ø§ØµÙ„ÛŒ

# Ù†Ù…Ø§ÛŒØ´ ÙØ§ÛŒÙ„ CSS
@app.route('/style.css')
def css():
    return send_from_directory('.', 'style.css', mimetype='text/css')

# Ù†Ù…Ø§ÛŒØ´ ÙØ§ÛŒÙ„ JavaScript
@app.route('/script.js')
def js():
    return send_from_directory('.', 'script.js', mimetype='application/javascript')

# Ù†Ù…Ø§ÛŒØ´ favicon.ico
@app.route('/favicon.ico')
def favicon():
    return send_from_directory('.', 'favicon.ico', mimetype='image/x-icon')

if __name__ == "__main__":
    app.run(debug=True)


# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Ø§ÛŒØ¬Ø§Ø¯ Ø§Ù¾Ù„ÛŒÚ©ÛŒØ´Ù† Flask
app = Flask(__name__)

# Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ SQLite Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ú©Ù†ÛŒØ¯
def init_db():
    conn = sqlite3.connect('site_manager.db')
    c = conn.cursor()
    c.execute('''CREATE TABLE IF NOT EXISTS logs (id INTEGER PRIMARY KEY, issue TEXT, timestamp DATETIME DEFAULT CURRENT_TIMESTAMP)''')
    c.execute('''CREATE TABLE IF NOT EXISTS insights (id INTEGER PRIMARY KEY, insight TEXT, timestamp DATETIME DEFAULT CURRENT_TIMESTAMP)''')
    c.execute('''CREATE TABLE IF NOT EXISTS status (id INTEGER PRIMARY KEY, website TEXT, status TEXT, timestamp DATETIME DEFAULT CURRENT_TIMESTAMP)''')
    conn.commit()
    conn.close()

init_db()

# Ú©Ù„Ø§Ø³ Ù…Ø¯ÛŒØ±ÛŒØª Ø³Ø§ÛŒØª Ø¨Ø±Ø§ÛŒ ØªØ¬Ø²ÛŒÙ‡ Ùˆ ØªØ­Ù„ÛŒÙ„ ÙˆØ¶Ø¹ÛŒØª Ø³Ø§ÛŒØª Ùˆ ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§
class WebsiteAnalyzer:
    def __init__(self, url, user_agent):
        self.url = url
        self.user_agent = user_agent
        self.errors = []
        self.performance_issues = []
        self.security_issues = []
        self.device_info = self.detect_device()

    def detect_device(self):
        parsed_user_agent = parse(self.user_agent)
        return {
            "browser": parsed_user_agent.browser.family,
            "os": parsed_user_agent.os.family,
            "device": parsed_user_agent.device.family
        }

    def log_issue(self, issue):
        conn = sqlite3.connect('site_manager.db')
        c = conn.cursor()
        c.execute('INSERT INTO logs (issue) VALUES (?)', (issue,))
        conn.commit()
        conn.close()

    def check_broken_links(self):
        try:
            response = requests.get(self.url)
            soup = BeautifulSoup(response.text, 'html.parser')
            links = [a.get('href') for a in soup.find_all('a', href=True)]
            for link in links:
                if not link.startswith('http'):
                    link = urljoin(self.url, link)
                try:
                    res = requests.head(link, timeout=5)
                    if res.status_code >= 400:
                        issue = f'Broken link: {link} (Status {res.status_code})'
                        self.errors.append(issue)
                        self.log_issue(issue)
                except requests.exceptions.RequestException:
                    issue = f'Unreachable link: {link}'
                    self.errors.append(issue)
                    self.log_issue(issue)
        except Exception as e:
            logging.error(f'Error checking broken links: {e}')

    def check_performance(self):
        start_time = time.time()
        try:
            response = requests.get(self.url, timeout=10)
            load_time = time.time() - start_time
            if load_time > 3:
                issue = f'Page load time is slow: {load_time:.2f} seconds'
                self.performance_issues.append(issue)
                self.log_issue(issue)
        except requests.exceptions.RequestException as e:
            issue = f'Performance issue: {e}'
            self.errors.append(issue)
            self.log_issue(issue)

    def check_security(self):
        try:
            response = requests.get(self.url)
            if 'X-Frame-Options' not in response.headers:
                issue = 'Security Warning: X-Frame-Options header missing'
                self.security_issues.append(issue)
                self.log_issue(issue)
            if 'Content-Security-Policy' not in response.headers:
                issue = 'Security Warning: Content-Security-Policy header missing'
                self.security_issues.append(issue)
                self.log_issue(issue)
        except Exception as e:
            logging.error(f'Error checking security: {e}')

    def analyze_trending_topics(self):
        news_sources = ["https://www.pcgamer.com/news/", "https://kotaku.com/c/gaming"]
        headlines = []
        for source in news_sources:
            try:
                response = requests.get(source)
                soup = BeautifulSoup(response.text, 'html.parser')
                headlines.extend([h.text.strip() for h in soup.find_all('h2')])
            except Exception as e:
                logging.error(f'Error fetching news from {source}: {e}')
        vectorizer = TfidfVectorizer(stop_words='english')
        X = vectorizer.fit_transform(headlines)
        kmeans = KMeans(n_clusters=3, random_state=42).fit(X)
        topics = kmeans.cluster_centers_.argsort()[:, ::-1]
        terms = vectorizer.get_feature_names_out()
        self.trending_topics = [terms[i] for i in topics[0][:5]]

    def analyze(self):
        self.check_broken_links()
        self.check_performance()
        self.check_security()
        self.analyze_trending_topics()
        return {
            "errors": self.errors,
            "performance_issues": self.performance_issues,
            "security_issues": self.security_issues,
            "device_info": self.device_info,
            "trending_topics": self.trending_topics
        }

# Ø§ÛŒØ¬Ø§Ø¯ Ø±ÙˆØª Ø¨Ø±Ø§ÛŒ ØªØ¬Ø²ÛŒÙ‡ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø³Ø§ÛŒØª
@app.route('/analyze', methods=['GET'])
def analyze():
    url = request.args.get('url')
    user_agent = request.headers.get('User-Agent', '')
    if not url:
        return jsonify({"error": "No URL provided"}), 400
    analyzer = WebsiteAnalyzer(url, user_agent)
    report = analyzer.analyze()
    return jsonify(report)

# Ø±ÙˆØªâ€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ùˆ ØµÙØ­Ø§Øª
@app.route('/')
def home():
    return render_template('index.html')

@app.route('/favicon.ico')
def favicon():
    return send_from_directory('.', 'favicon.ico')

@app.route('/style.css')
def style():
    return send_from_directory('.', 'style.css')

@app.route('/js.js')
def script():
    return send_from_directory('.', 'js.js')

# Ø§Ø¬Ø±Ø§ÛŒ Ø§Ù¾Ù„ÛŒÚ©ÛŒØ´Ù† Flask
if __name__ == '__main__':
    app.run(debug=True)
